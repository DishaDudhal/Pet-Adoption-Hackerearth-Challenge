{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "train_file_path = 'C:\\\\Users\\\\disha\\\\Documents\\\\Datasets\\\\Pet Adoption\\\\Dataset\\\\train.csv'  # Enter training file path\n",
    "test_file_path = 'C:\\\\Users\\\\disha\\\\Documents\\\\Datasets\\\\Pet Adoption\\\\Dataset\\\\test.csv' # Enter Test file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Before Balancing:  Counter({0: 8999, 1: 8356, 2: 1477})\n",
      "Before Balancing:  Counter({2: 10621, 1: 7182, 4: 941, 0: 88})\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Implementation with respect to MLP\n",
    "\n",
    "num_neighbors = 10   #neighbors for KNN Imputer\n",
    "df_train = pd.read_csv(train_file_path)\n",
    "#df_train.groupby(['pet_category']).agg(['count'])\n",
    "df_train.head()\n",
    "df_train.tail()\n",
    "\n",
    "#drop pet_id\n",
    "df_train.drop(columns=['pet_id'],inplace=True)\n",
    "\n",
    "#label encode color_type\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df_train['color_type'])\n",
    "df_train['color_type'] = label_encoder.transform(df_train['color_type'])\n",
    "\n",
    "#get into datetime format and save only date\n",
    "df_train['issue_date'] = pd.to_datetime(df_train['issue_date'])\n",
    "df_train['listing_date'] = pd.to_datetime(df_train['listing_date'])\n",
    "df_train['issue_date'] = pd.to_datetime(df_train['issue_date'].dt.date)\n",
    "df_train['listing_date'] = pd.to_datetime(df_train['listing_date'].dt.date)\n",
    "\n",
    "#fill null values by KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=num_neighbors)\n",
    "df_train['condition'] = imputer.fit_transform(df_train.iloc[:,2:3])\n",
    "\n",
    "#get count where issue date is after listing date\n",
    "print((df_train['listing_date']<=df_train['issue_date']).sum())\n",
    "\n",
    "#Drop rows where issue date is after listing date\n",
    "df_train = df_train.loc[(df_train['listing_date']>=df_train['issue_date'])].copy()\n",
    "#create new column with difference between issue date and listing date\n",
    "df_train['gap'] = (df_train['listing_date'] - df_train['issue_date']).dt.total_seconds()/(60*60*24)\n",
    "df_train = pd.concat([df_train.iloc[:,:2],df_train.iloc[:,10:],df_train.iloc[:,2:10]],axis=1).copy()\n",
    "\n",
    "#drop issue date and listing date and color type\n",
    "df_train.drop(columns=['issue_date','listing_date'],inplace=True)\n",
    "df_train.head()\n",
    "\n",
    "#df_train = df_train[(z < 3).all(axis=1)]\n",
    "\n",
    "#one hot encoding\n",
    "Y = df_train.iloc[:,-2:].to_numpy()\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [2])], remainder='passthrough') \n",
    "columnTransformer.fit(df_train.iloc[:,:-2])\n",
    "df_train = columnTransformer.transform(df_train.iloc[:,:-2]).toarray()\n",
    "df_train = np.concatenate((df_train,Y),axis=1)\n",
    "\n",
    "\n",
    "col = list(range(56))\n",
    "col_names = col + ['gap','condition','length(m)','height(cm)','X1','X2','breed_category','pet_category']\n",
    "df_train = pd.DataFrame(df_train,columns=col_names)\n",
    "df_train = pd.concat([df_train.iloc[:,56:58],df_train.iloc[:,:56],df_train.iloc[:,58:]],axis=1)\n",
    "\n",
    "\n",
    "#change dtype of breed_category and pet category\n",
    "df_train['breed_category'] = df_train['breed_category'].astype('int64')\n",
    "df_train['pet_category'] = df_train['pet_category'].astype('int64')\n",
    "df_train.tail()\n",
    "\n",
    "df_train.isnull().sum().sum()\n",
    "\n",
    "#check correlation\n",
    "df_train.corr()\n",
    "\n",
    "df1 = df_train.drop(columns=['pet_category'])\n",
    "\n",
    "x_train1 = df1.iloc[:,:-1]\n",
    "y_train1 = df1.iloc[:,-1:]\n",
    "print('Before Balancing: ',Counter(y_train1['breed_category']))\n",
    "\n",
    "# over1 = SMOTE(sampling_strategy={0:9000,1:8357,2:6000})\n",
    "# under1 = RandomUnderSampler(sampling_strategy={0:6000,1:6000,2:6000})\n",
    "# steps1 = [('o', over1), ('u', under1)]\n",
    "# pipeline = Pipeline(steps=steps1)\n",
    "# x_train1, y_train1 = pipeline.fit_resample(x_train1, y_train1)\n",
    "\n",
    "# over1 = SMOTE()\n",
    "# x_train1,y_train1 = over1.fit_resample(x_train1,y_train1)\n",
    "# print('After Balancing: ',Counter(y_train1))\n",
    "\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler1.fit(x_train1)\n",
    "x_train1 = scaler1.transform(x_train1)\n",
    "\n",
    "df2 = df_train\n",
    "\n",
    "x_train2 = df2.iloc[:,:-1]\n",
    "y_train2 = df2.iloc[:,-1:]\n",
    "print('Before Balancing: ',Counter(y_train2['pet_category']))\n",
    "\n",
    "# over2 = SMOTE(sampling_strategy={0:6000,1:7184,2:10621,4:6000})\n",
    "# under2 = RandomUnderSampler(sampling_strategy={0:6000,1:6000,2:6000,4:6000})\n",
    "# steps2 = [('o', over2), ('u', under2)]\n",
    "# pipeline = Pipeline(steps=steps2)\n",
    "# x_train2, y_train2 = pipeline.fit_resample(x_train2, y_train2)\n",
    "\n",
    "# over2 = SMOTE()\n",
    "# x_train2,y_train2 = over2.fit_resample(x_train2,y_train2)\n",
    "# print('After Balancing: ',Counter(y_train2))\n",
    "\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler2.fit(x_train2)\n",
    "x_train2 = scaler2.transform(x_train2)\n",
    "\n",
    "#Using MLP classfier\n",
    "model1 = MLPClassifier()\n",
    "model1.fit(x_train1,y_train1)\n",
    "\n",
    "model2 = MLPClassifier()\n",
    "model2.fit(x_train2,y_train2)\n",
    "\n",
    "df_test = pd.read_csv(test_file_path)\n",
    "df_test.head()\n",
    "\n",
    "#drop pet_id\n",
    "temp_df_test = df_test.drop(columns=['pet_id'])\n",
    "#label encode\n",
    "temp_df_test['color_type'] = label_encoder.transform(temp_df_test['color_type'])\n",
    "\n",
    "#get into datetime format and save only date\n",
    "temp_df_test['issue_date'] = pd.to_datetime(temp_df_test['issue_date'])\n",
    "temp_df_test['listing_date'] = pd.to_datetime(temp_df_test['listing_date'])\n",
    "temp_df_test['issue_date'] = pd.to_datetime(temp_df_test['issue_date'].dt.date)\n",
    "temp_df_test['listing_date'] = pd.to_datetime(temp_df_test['listing_date'].dt.date)\n",
    "\n",
    "#fill null values by mode \n",
    "#l=temp_df_test.filter(['issue_date','listing_date','condition','color_type','length(m)','height(cm)','X1','X2']).mode()\n",
    "#temp_df_test[['issue_date','listing_date','condition','color_type','length(m)','height(cm)','X1','X2']]=temp_df_test[['issue_date','listing_date','condition','color_type','length(m)','height(cm)','X1','X2']].fillna(value=l.iloc[0])\n",
    "temp_df_test['condition'] = imputer.transform(temp_df_test.iloc[:,2:3])\n",
    "\n",
    "#get count where issue date is after listing date\n",
    "print((temp_df_test['listing_date']<=temp_df_test['issue_date']).sum())\n",
    "\n",
    "#Drop rows where issue date is after listing date\n",
    "temp_df_test = temp_df_test.loc[(temp_df_test['listing_date']>=temp_df_test['issue_date'])].copy()\n",
    "#create new column with difference between issue date and listing date\n",
    "temp_df_test['gap'] = (temp_df_test['listing_date'] - temp_df_test['issue_date']).dt.total_seconds()/(60*60*24)\n",
    "temp_df_test = pd.concat([temp_df_test.iloc[:,:2],temp_df_test.iloc[:,8:],temp_df_test.iloc[:,2:8]],axis=1)\n",
    "\n",
    "#drop issue date and listing date\n",
    "temp_df_test.drop(columns=['issue_date','listing_date'],inplace=True)\n",
    "\n",
    "#one hot encoding\n",
    "temp_df_test = columnTransformer.transform(temp_df_test).toarray()\n",
    "\n",
    "col = list(range(56))\n",
    "col_names = col + ['gap','condition','length(m)','height(cm)','X1','X2']\n",
    "temp_df_test = pd.DataFrame(temp_df_test,columns=col_names)\n",
    "temp_df_test = pd.concat([temp_df_test.iloc[:,56:58],temp_df_test.iloc[:,:56],temp_df_test.iloc[:,58:]],axis=1)\n",
    "temp_df_test.tail()\n",
    "\n",
    "x_test1 = scaler1.transform(temp_df_test)\n",
    "pred1 = model1.predict(x_test1)\n",
    "pred1_df = pd.DataFrame(pred1,columns=['breed_category'])\n",
    "df_test = pd.concat([df_test,pred1_df],axis=1)\n",
    "\n",
    "temp_df_test = pd.concat([temp_df_test,pred1_df],axis=1)\n",
    "x_test2 = scaler2.transform(temp_df_test)\n",
    "pred2 = model2.predict(x_test2)\n",
    "pred2_df = pd.DataFrame(pred2,columns=['pet_category'])\n",
    "df_test = pd.concat([df_test,pred2_df],axis=1)\n",
    "\n",
    "df_test['breed_category'] = df_test['breed_category'].astype('float64')\n",
    "df_test.drop(columns=['issue_date','listing_date','condition','color_type','length(m)','height(cm)','X1','X2'],inplace=True)\n",
    "df_test.head()\n",
    "\n",
    "df_test.to_csv('C:\\\\Users\\\\disha\\\\Downloads\\\\output_mlp_imputer10.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Before Balancing:  Counter({0: 8999, 1: 8356, 2: 1477})\n",
      "Before Balancing:  Counter({2: 10621, 1: 7182, 4: 941, 0: 88})\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Output using XG Boost algorithm\n",
    "\n",
    "num_neighbors = 10\n",
    "df_train = pd.read_csv('C:\\\\Users\\\\disha\\\\Documents\\\\Datasets\\\\Pet Adoption\\\\Dataset\\\\train.csv')\n",
    "#df_train.groupby(['pet_category']).agg(['count'])\n",
    "df_train.head()\n",
    "df_train.tail()\n",
    "\n",
    "#drop pet_id\n",
    "df_train.drop(columns=['pet_id'],inplace=True)\n",
    "\n",
    "#label encode color_type\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df_train['color_type'])\n",
    "df_train['color_type'] = label_encoder.transform(df_train['color_type'])\n",
    "\n",
    "#get into datetime format and save only date\n",
    "df_train['issue_date'] = pd.to_datetime(df_train['issue_date'])\n",
    "df_train['listing_date'] = pd.to_datetime(df_train['listing_date'])\n",
    "df_train['issue_date'] = pd.to_datetime(df_train['issue_date'].dt.date)\n",
    "df_train['listing_date'] = pd.to_datetime(df_train['listing_date'].dt.date)\n",
    "\n",
    "#fill null values by mode \n",
    "#l=df_train.filter(['issue_date','listing_date','condition','color_type','length(m)','height(cm)','X1','X2','breed_category','pet_category']).mode()\n",
    "#df_train[['issue_date','listing_date','condition','color_type','length(m)','height(cm)','X1','X2','breed_category','pet_category']]=df_train[['issue_date','listing_date','condition','color_type','length(m)','height(cm)','X1','X2','breed_category','pet_category']].fillna(value=l.iloc[0])\n",
    "#fill values by imputer\n",
    "imputer = KNNImputer(n_neighbors=num_neighbors)\n",
    "df_train['condition'] = imputer.fit_transform(df_train.iloc[:,2:3])\n",
    "\n",
    "#get count where issue date is after listing date\n",
    "print((df_train['listing_date']<=df_train['issue_date']).sum())\n",
    "\n",
    "#Drop rows where issue date is after listing date\n",
    "df_train = df_train.loc[(df_train['listing_date']>=df_train['issue_date'])].copy()\n",
    "#create new column with difference between issue date and listing date\n",
    "df_train['gap'] = (df_train['listing_date'] - df_train['issue_date']).dt.total_seconds()/(60*60*24)\n",
    "df_train = pd.concat([df_train.iloc[:,:2],df_train.iloc[:,10:],df_train.iloc[:,2:10]],axis=1).copy()\n",
    "\n",
    "#drop issue date and listing date and color type\n",
    "df_train.drop(columns=['issue_date','listing_date'],inplace=True)\n",
    "df_train.head()\n",
    "\n",
    "'''\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "z = np.abs(stats.zscore(df_train))\n",
    "print(z)\n",
    "'''\n",
    "\n",
    "#df_train = df_train[(z < 3).all(axis=1)]\n",
    "#df_train.shape\n",
    "\n",
    "#one hot encoding\n",
    "Y = df_train.iloc[:,-2:].to_numpy()\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [2])], remainder='passthrough') \n",
    "columnTransformer.fit(df_train.iloc[:,:-2])\n",
    "df_train = columnTransformer.transform(df_train.iloc[:,:-2]).toarray()\n",
    "df_train = np.concatenate((df_train,Y),axis=1)\n",
    "\n",
    "\n",
    "col = list(range(56))\n",
    "col_names = col + ['gap','condition','length(m)','height(cm)','X1','X2','breed_category','pet_category']\n",
    "df_train = pd.DataFrame(df_train,columns=col_names)\n",
    "df_train = pd.concat([df_train.iloc[:,56:58],df_train.iloc[:,:56],df_train.iloc[:,58:]],axis=1)\n",
    "\n",
    "\n",
    "#change dtype of breed_category and pet category\n",
    "df_train['breed_category'] = df_train['breed_category'].astype('int64')\n",
    "df_train['pet_category'] = df_train['pet_category'].astype('int64')\n",
    "df_train.tail()\n",
    "\n",
    "df_train.isnull().sum().sum()\n",
    "\n",
    "#check correlation\n",
    "df_train.corr()\n",
    "\n",
    "df1 = df_train.drop(columns=['pet_category'])\n",
    "\n",
    "x_train1 = df1.iloc[:,:-1]\n",
    "y_train1 = df1.iloc[:,-1:]\n",
    "print('Before Balancing: ',Counter(y_train1['breed_category']))\n",
    "\n",
    "# over1 = SMOTE(sampling_strategy={0:9000,1:8357,2:6000})\n",
    "# under1 = RandomUnderSampler(sampling_strategy={0:6000,1:6000,2:6000})\n",
    "# steps1 = [('o', over1), ('u', under1)]\n",
    "# pipeline = Pipeline(steps=steps1)\n",
    "# x_train1, y_train1 = pipeline.fit_resample(x_train1, y_train1)\n",
    "\n",
    "# over1 = SMOTE()\n",
    "# x_train1,y_train1 = over1.fit_resample(x_train1,y_train1)\n",
    "# print('After Balancing: ',Counter(y_train1))\n",
    "\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler1.fit(x_train1)\n",
    "x_train1 = scaler1.transform(x_train1)\n",
    "\n",
    "df2 = df_train\n",
    "\n",
    "x_train2 = df2.iloc[:,:-1]\n",
    "y_train2 = df2.iloc[:,-1:]\n",
    "print('Before Balancing: ',Counter(y_train2['pet_category']))\n",
    "\n",
    "# over2 = SMOTE(sampling_strategy={0:6000,1:7184,2:10621,4:6000})\n",
    "# under2 = RandomUnderSampler(sampling_strategy={0:6000,1:6000,2:6000,4:6000})\n",
    "# steps2 = [('o', over2), ('u', under2)]\n",
    "# pipeline = Pipeline(steps=steps2)\n",
    "# x_train2, y_train2 = pipeline.fit_resample(x_train2, y_train2)\n",
    "\n",
    "# over2 = SMOTE()\n",
    "# x_train2,y_train2 = over2.fit_resample(x_train2,y_train2)\n",
    "# print('After Balancing: ',Counter(y_train2))\n",
    "\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler2.fit(x_train2)\n",
    "x_train2 = scaler2.transform(x_train2)\n",
    "\n",
    "#Using XGB Classifier\n",
    "model1 = XGBClassifier()\n",
    "model1.fit(x_train1,y_train1)\n",
    "\n",
    "model2 = XGBClassifier()\n",
    "model2.fit(x_train2,y_train2)\n",
    "\n",
    "df_test = pd.read_csv('C:\\\\Users\\\\disha\\\\Documents\\\\Datasets\\\\Pet Adoption\\\\Dataset\\\\test.csv')\n",
    "df_test.head()\n",
    "\n",
    "#drop pet_id\n",
    "temp_df_test = df_test.drop(columns=['pet_id'])\n",
    "#label encode\n",
    "temp_df_test['color_type'] = label_encoder.transform(temp_df_test['color_type'])\n",
    "\n",
    "#get into datetime format and save only date\n",
    "temp_df_test['issue_date'] = pd.to_datetime(temp_df_test['issue_date'])\n",
    "temp_df_test['listing_date'] = pd.to_datetime(temp_df_test['listing_date'])\n",
    "temp_df_test['issue_date'] = pd.to_datetime(temp_df_test['issue_date'].dt.date)\n",
    "temp_df_test['listing_date'] = pd.to_datetime(temp_df_test['listing_date'].dt.date)\n",
    "\n",
    "#fill null values by mode \n",
    "#l=temp_df_test.filter(['issue_date','listing_date','condition','color_type','length(m)','height(cm)','X1','X2']).mode()\n",
    "#temp_df_test[['issue_date','listing_date','condition','color_type','length(m)','height(cm)','X1','X2']]=temp_df_test[['issue_date','listing_date','condition','color_type','length(m)','height(cm)','X1','X2']].fillna(value=l.iloc[0])\n",
    "temp_df_test['condition'] = imputer.transform(temp_df_test.iloc[:,2:3])\n",
    "\n",
    "#get count where issue date is after listing date\n",
    "print((temp_df_test['listing_date']<=temp_df_test['issue_date']).sum())\n",
    "\n",
    "#Drop rows where issue date is after listing date\n",
    "temp_df_test = temp_df_test.loc[(temp_df_test['listing_date']>=temp_df_test['issue_date'])].copy()\n",
    "#create new column with difference between issue date and listing date\n",
    "temp_df_test['gap'] = (temp_df_test['listing_date'] - temp_df_test['issue_date']).dt.total_seconds()/(60*60*24)\n",
    "temp_df_test = pd.concat([temp_df_test.iloc[:,:2],temp_df_test.iloc[:,8:],temp_df_test.iloc[:,2:8]],axis=1)\n",
    "\n",
    "#drop issue date and listing date\n",
    "temp_df_test.drop(columns=['issue_date','listing_date'],inplace=True)\n",
    "\n",
    "#one hot encoding\n",
    "temp_df_test = columnTransformer.transform(temp_df_test).toarray()\n",
    "\n",
    "col = list(range(56))\n",
    "col_names = col + ['gap','condition','length(m)','height(cm)','X1','X2']\n",
    "temp_df_test = pd.DataFrame(temp_df_test,columns=col_names)\n",
    "temp_df_test = pd.concat([temp_df_test.iloc[:,56:58],temp_df_test.iloc[:,:56],temp_df_test.iloc[:,58:]],axis=1)\n",
    "temp_df_test.tail()\n",
    "\n",
    "x_test1 = scaler1.transform(temp_df_test)\n",
    "pred1 = model1.predict(x_test1)\n",
    "pred1_df = pd.DataFrame(pred1,columns=['breed_category'])\n",
    "df_test = pd.concat([df_test,pred1_df],axis=1)\n",
    "\n",
    "temp_df_test = pd.concat([temp_df_test,pred1_df],axis=1)\n",
    "x_test2 = scaler2.transform(temp_df_test)\n",
    "pred2 = model2.predict(x_test2)\n",
    "pred2_df = pd.DataFrame(pred2,columns=['pet_category'])\n",
    "df_test = pd.concat([df_test,pred2_df],axis=1)\n",
    "\n",
    "df_test['breed_category'] = df_test['breed_category'].astype('float64')\n",
    "df_test.drop(columns=['issue_date','listing_date','condition','color_type','length(m)','height(cm)','X1','X2'],inplace=True)\n",
    "df_test.head()\n",
    "\n",
    "df_test.to_csv('C:\\\\Users\\\\disha\\\\Downloads\\\\output_xgb_imputer10.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
